{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the coding demonstration from the Plant Cell Atlas. As you can see, you are running a Jupyter Notebook through Google Colab, a free service from Google. A Jupyter Notebook is a useful coding tool that allows you to run code in small blocks, which can be helpful for data science  where you make a lot of small changes and need to see the results midway through. You also have markdown blocks, like this one, which you can use to make headings and other text descriptions. IDEs will even let you jump between headings like bookmarks. \n",
    "\n",
    "---\n",
    "\n",
    "While we are currently on Google Colab, you can also run Jupyter Notebooks locally or on a remote server. \n",
    "\n",
    "---\n",
    "\n",
    "Although Jupyter Notebooks are very useful tools, its important to keep in mind that they have some drawbacks. Code blocks are executed in the order you run them, and can be executed multiple times or in arbitrary orders, so if you aren't careful you can end up making unintentional changes to your code without even realizing it. You should make sure you run cells in the order they are in your notebook to ensure your codes works as you expect it to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will look at some heading sizes available. These are done by putting a number sign \"#\" at the start of the line. More \"#\" makes the heading smaller\n",
    "\n",
    "# Markdown Heading 1 \n",
    "\n",
    "## Markdown Heading 2 \n",
    "\n",
    "### Markdown Heading 3 \n",
    "\n",
    "You can also **bold text** put putting double asterisks around it, and *italicize* with single asterisks, and almost any other text or table formatting. You can also easily insert links, do quotes, and insert images. \n",
    "\n",
    "---\n",
    "\n",
    "Double click on this box to see the source text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number signs set off comments in Python. Below we use \"!\" to run shell commands from within a Jupyter notebook cell.\n",
    "# We are fetching our data and installing packages we need. \n",
    "\n",
    "!pip install scanpy\n",
    "!pip install leidenalg\n",
    "!mkdir data\n",
    "!wget https://zenodo.org/records/18553930/files/arabidopsis_data.h5ad -O data/arabidopsis_data.h5ad\n",
    "\n",
    "!cd data\n",
    "!mkdir write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "import itertools\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to set up our random seeds for reproducibility. Some processes initialize randomly, so to ensure that \n",
    "we can reproduce our results, we set the random state and will use it in our code. Once you have preliminary results,\n",
    "you should check that your results are robust to different random states. It is rare to find results that are \n",
    "sensitive to the random state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1789\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to set up some thresholds up front. By defining them early, we tell someone reading out notebook about our assumptions so they aren't buried deep in code. It also lets us change them easily, without having to search through the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Thresholds\n",
    "min_genes_per_cell = 2000\n",
    "min_cells_per_gene = 5\n",
    "max_different_genes_per_cell = 6000\n",
    "max_pct_counts_mt = 1\n",
    "# Highly Variable Gene Selection Thresholds\n",
    "highly_variable_gene_min_mean = 0.0125\n",
    "highly_variable_gene_max_mean = 3\n",
    "highly_variable_gene_min_disp = 1\n",
    "# Clustering Parameters\n",
    "number_of_neighbors = 10\n",
    "n_of_pca_components = 40\n",
    "clustering_resolution = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = (\n",
    "    3  # Tell scanpy we want it to be chatty today and inform us what's going on\n",
    ")\n",
    "sc.set_figure_params(\n",
    "    facecolor=\"white\", figsize=(5, 5)\n",
    ")  # Make figures bigger and on a white background"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets read in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\n",
    "    \"data/arabidopsis_data.h5ad\",\n",
    ")\n",
    "adata.obs = adata.obs.drop(columns=[\"fastq_1\", \"fastq_2\", \"expected_cells\"])\n",
    "adata.var = adata.var.drop(columns=[\"genome\", \"gene_versions\", \"feature_types\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in case our annotation has overlapping gene symbols, we are going to make the gene symbols unique for any symbols with duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()  ## This adds a number after duplicate variable names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets explore the structure of our data a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata  # General Object view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our AnnData Object stats off pretty empty. Its got the data matrix under adata.X, the cell barcodes and batches under .obs, and the gene symbols and gene IDs under .var. Lets explore those additional aspects of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(adata.obs))  # Prints the datatype of the observation section of the AnnData\n",
    "display(adata.obs)  # Returns the observation section of the AnnData\n",
    "print(\n",
    "    adata.obs[\"sample\"].unique()\n",
    ")  # Prints the unique values in the \"sample\" column of the observation section of the AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(adata.var))  ## Prints the Object type of the Variables of the AnnData\n",
    "adata.var  ## Returns view of the variables of the AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(adata.X))  ## Prints the object type of the data matrix of the AnnData\n",
    "adata.X  ## Returns view of the data matrix of the AnnData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have two familiar data types, Pandas, and one that is a bit different, a sparse matrix. Because a single cell experiment has ~ 30,000 variables for each cell sequence, the matrix rapidly becomes huge as you add cells to it. However, you have zero reads for most genes in most cells, so our matrix is very sparse. Storing each individual zero is computationally taxing, so we use a sparse matrix to manage this behind the scenes for us. However, we will need to keep this in mind for cases and actions that require a dense matrix \n",
    "\n",
    "Next, we'll look at some initial info about our experiment, and look at how sparse the matrix is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_matrix = pd.DataFrame(\n",
    "    data=adata.X.todense()\n",
    ")  # convert dense matrix to sparse to view\n",
    "dense_matrix.iloc[0:30, :20]  ## View the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_matrix.shape  ## View the dimensions of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dense_matrix > 0).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the length and width of the matrix\n",
    "dense_matrix_width = dense_matrix.shape[1]\n",
    "dense_matrix_length = dense_matrix.shape[0]\n",
    "\n",
    "total_size_of_matrix = (\n",
    "    dense_matrix_width * dense_matrix_length\n",
    ")  ## Calculate total number of values in matrix\n",
    "\n",
    "# check what positions are non zero\n",
    "non_zero_dense_matrix = dense_matrix > 0\n",
    "\n",
    "# Sum the number of non zero positions\n",
    "filled_posistions = (\n",
    "    non_zero_dense_matrix.sum().sum()\n",
    ")  ### The number of cells with a non zero value\n",
    "percent_of_matrix_filled = (\n",
    "    filled_posistions / total_size_of_matrix\n",
    ") * 100  ## You remember what a percentage is\n",
    "print(\n",
    "    f\"Our Matrix only has a value at {round(percent_of_matrix_filled,3)}% of posistions!\"\n",
    ")  # Round number and print it with an fstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highest_expr_genes(\n",
    "    adata, n_top=20\n",
    ")  # Use builtin scanpy plotting function to visualize genes with the most reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take 5 minutes, everyone look up what the first gene does. If you can, look up where it tends to be localized (Suba can help with this). What might this indicate about the data?  Also look at the distribution of counts per cell and think about what that means. What is each dot on the graph? Now pick any After five minutes we will ask everyone what their gene does and if they think it makes sense to be so highly expressed. If you'd like, guess what the experimental treatment for this dataset was. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots our most expressed genes, letting us get an idea if our experiment had anything go dramatically wrong. For example, if your most expressed genes were all stress genes, you might be concerned you mishandled cells prior to sequencing.\n",
    "\n",
    "In a normal workflow, this might be where you peform background detection. Some RNA has a tendency to leak out of the cells/nuclei and into the ambient fluid. This ambient RNA then gets mixed with every cell's profile. This is especially problematic for marker detection, where broad detection of a gene might cause you to rule it out as a marker. For this, I would recommend CellBender or SoupX. CellBender is substantially more computationally intensive than SoupX. \n",
    "\n",
    "\n",
    "Before we keep going, we are going to remove cells and genes that we aren't interested in. For genes, we are only interested in genes that are in our dataset in at least a few cells, a gene in a single cell doesn't tell us much. We are also only interested in cells with enough reads to be able to cluster them. We might also remove genes with high mitochondrial signal (eg. the first gene) as this can indicate the cells are dying or low quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(\n",
    "    adata, min_genes=min_genes_per_cell\n",
    ")  # Filter cells with less than 1000 genes expressed\n",
    "sc.pp.filter_genes(\n",
    "    adata, min_cells=min_cells_per_gene\n",
    ")  # Filter genes expressed in less than 5 cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets explore our cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we've trimmed out genes that weren't expressed in our data! We also trimmed some cells that have low expression. I will note that our cell threshold is quite high, as this data has already been preprocessed somewhat. We've also added some columns to our Pandas describing our cells and our genes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"AT1G07590\")\n",
    "# annotate the gene we identified as mitochondrial so we can remove it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\"], percent_top=None, log1p=False, inplace=True\n",
    ")  ### This calculates several QC metrics all at once, based on what genes we feed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A peak at the metrics we calculated\n",
    "The number of genes expressed in the count matrix - different because n_genes was calculated before filtering\n",
    "The total counts per cell\n",
    "The percentage of counts in mitochondrial genes\n",
    " now lets visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(\n",
    "    adata,\n",
    "    [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"],\n",
    "    jitter=0.4,\n",
    "    multi_panel=True,\n",
    ")  ## Use built in plotting function to visualize the QC metrics we calculated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to remove genes with too many counts, as these could be droplets that got too many cells or another technical artifact. We also want to remove cells with too much mitochondrial DNA, as this indicates the cells are undergoing apoptosis. As an alternative to threshold based approaches, you might use a doublet detector like DoubletFinder or DoubletDetection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[\n",
    "    adata.obs.n_genes_by_counts < max_different_genes_per_cell, :\n",
    "]  ## Remove cells with more than 2500 counts (This is dated don't use this threshold on modern data)\n",
    "adata = adata[\n",
    "    adata.obs.pct_counts_mt < max_pct_counts_mt, :\n",
    "]  # Remove cells with more than 5 % Mito reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've finished filtering, so we're gonna save our object at this step. It is important to save intermediate objects in case you have an issue with your pipeline and need to repair it later, or if you just want to re-do some analysis without running the entire thing. Changes to packages might happen that break code and you don't want to have to spend days getting it working again!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\n",
    "    \"write/pbmc3k_filtered.h5ad\",\n",
    "    convert_strings_to_categoricals=False,\n",
    ")  # Making strings categories saves a lot of space!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will normalize the data , and logarithmize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(\n",
    "    adata, target_sum=1e4\n",
    ")  ## Scale counts in each cell to sum to 10,000 for comparisons between cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(\n",
    "    adata\n",
    ")  ## Log+1 transforms the data - this deals with zero counts since log(0) doesn't exist, without impacting rest of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to identify cell clusters we need to use genes that are different between cells. A gene that is expressed at the same level in every cell isn't useful for distinguishing them. So lets find our highly variable genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    min_mean=highly_variable_gene_min_mean,\n",
    "    max_mean=highly_variable_gene_max_mean,\n",
    "    min_disp=highly_variable_gene_min_disp,\n",
    ")  # Identify highly variable genes based on mean and dispersion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds a lot of info to our .var, lets check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(\n",
    "    adata\n",
    ")  # Use Built in plotting function to visualize highly variable genes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've found our highly variable genes, lets begin to reduce the dimensionality of our data I'll explain PCA. We are going to skim over the nearest neighbors, as it is very intutitive. However, we will discuss UMAPs and their limitations as 2D projections of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(\n",
    "    adata, svd_solver=\"arpack\", random_state=random_state\n",
    ")  ## Identifies nearest neighbors of each cell based on PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.pca_variance_ratio(adata) #Visualize contribution of PCAs to variance - uncomment if curious will not affect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(\n",
    "    adata,\n",
    "    n_neighbors=number_of_neighbors,\n",
    "    n_pcs=n_of_pca_components,\n",
    "    random_state=random_state,\n",
    ")  # Finds Distances in multidimensional space between cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(\n",
    "    adata, random_state=random_state\n",
    ")  # Visualizes cells in multidimensional space as 2d embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(\n",
    "    adata, resolution=clustering_resolution, random_state=random_state\n",
    ")  # Clusters cells by distance in multidimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"leiden\"])  # Visiualize Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, lets take 10 minutes to play with the clustering settings and see how things change. Try changing resolution, n_neighbors, and n_pca one at a time and see how it changes the data. Do it one and a time and then in combination. Also try changing the highly variable gene selection cut offs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\n",
    "    \"/write/pbmc3k_clustered.h5ad\",\n",
    "    convert_strings_to_categoricals=False,\n",
    ")  # We are saving our object again after clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try and identify one of the clusters, using 3 markers for root cortex cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata, color=[\"leiden\", \"AT1G27030\", \"AT1G02850\", \"AT1G05570\"]\n",
    ")  # Visualize clustering and Attempt to Identify Cortex Cells By expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take 5 minutes and let everyone plot some genes on their own. You can takes genes from above, where we looked at the most expressed genes, or pick genes that you know or like. Plot a couple of genes on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata, color=[\"#####\", \"#####\", \"#####\"]\n",
    ")  # shows embedding with cells colored by expression of 3 marker genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cluster_names = {\"1\": \"Cortex\"}\n",
    "adata.obs[\"leiden\"] = adata.obs[\"leiden\"].replace(\n",
    "    new_cluster_names\n",
    ")  ## Replace the cluster name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"leiden\",\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=\"x-small\",\n",
    "    title=\"Identified Cell Clusters\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clusters, we can do things like find marker genes, ID cell types, and do differential gene expression. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key tool to understand is psuedobulking data. Psuedobulking helps handle the sparsity of single-cell data while also being more intuitive to handle statistically. If you want to compare two cell types, you might think to treat each cell as a sample, and do your statistics that way. However, this would provide you with dramatically more confidence in your estimate than is real, as the cells in a cluster are not independent. Instead, we psuedobulk, allowing us to reduce sparsity and reduce the cells to true idependent samples, based on batch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to create some fake batches and assign cells to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Batch\"] = np.random.randint(\n",
    "    low=1, high=4, size=len(adata.obs)\n",
    ")  # Assign random batches - do you know why high is 4?\n",
    "adata.obs.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata, color=\"Batch\", legend_fontsize=\"x-small\", title=\"Fake Batches\", s=400\n",
    ")  # Notice the overplotting when using the batch as an integer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Batch Str\"] = adata.obs[\"Batch\"].astype(\n",
    "    str\n",
    ")  # Change the batch type to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata, color=\"Batch Str\", legend_fontsize=\"x-small\", title=\"Fake Batches\", s=400\n",
    ")  # overplotting resolved! Think of this when plotting a metadata variable on single cell data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop through the batches and build a dataframe. Note that this code assumes all clusters contain all batches - This might not be true!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = adata.obs[\"leiden\"].unique()  # Get cluster names\n",
    "batches = adata.obs[\"Batch\"].unique()  # Get batch IDs\n",
    "all_samples = list(\n",
    "    itertools.product(clusters, batches)\n",
    ")  # Generate list of all combinations of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psuedobulk_df = pd.DataFrame(\n",
    "    index=adata.var_names\n",
    ")  ## Make a base dataframe index we will add stuff on to later\n",
    "psuedobulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_type in all_samples:\n",
    "\n",
    "    ## Read in the Names so our code is easy to understand\n",
    "    current_cluster = batch_type[0]\n",
    "    current_batch = batch_type[1]\n",
    "\n",
    "    ## Calculate the Psuedobulked mean\n",
    "    cells_matching_batch_and_cluster = adata[\n",
    "        (adata.obs[\"leiden\"] == current_cluster) & (adata.obs[\"Batch\"] == current_batch)\n",
    "    ]\n",
    "    mean_of_genes = cells_matching_batch_and_cluster.X.mean(axis=0).tolist()[0]\n",
    "\n",
    "    name_of_combo = (\n",
    "        \"Cluster number \" + current_cluster + \" \" + \"Batch Number \" + str(current_batch)\n",
    "    )\n",
    "    psuedobulk_df[name_of_combo] = mean_of_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\n",
    "    \"write/pbmc3k_final.h5ad\",\n",
    "    convert_strings_to_categoricals=False,\n",
    ")  # Save our final object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psuedobulk_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Single_cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
